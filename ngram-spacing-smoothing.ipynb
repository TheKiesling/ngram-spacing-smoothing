{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa56939",
   "metadata": {},
   "source": [
    "# Ngram Spacing and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0239771",
   "metadata": {},
   "source": [
    "### José Pablo Kiesling Lange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadfcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm import KneserNeyInterpolated\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a02488",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61eefee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\TheKi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TheKi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('cess_esp')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7add29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_nltk = cess_esp.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787263b",
   "metadata": {},
   "source": [
    "## Estandarización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874093d",
   "metadata": {},
   "source": [
    "Para ver la efectivdad de la estandarización, se mostrará las 10 palabras más frecuentes del corpus antes y después de la estandarización. El objetivo es ver si hay modificación en la cantidad de dichas palabras o si una nueva palabra aparece con frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d8d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2567f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(corpus, n=10):\n",
    "    words = [word for line in corpus for word in line.split()]\n",
    "    most_common = Counter(words).most_common(n)\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b12f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 11420),\n",
       " ('de', 10234),\n",
       " ('la', 6412),\n",
       " ('.', 5866),\n",
       " ('que', 5552),\n",
       " ('el', 5199),\n",
       " ('en', 4340),\n",
       " ('y', 4235),\n",
       " ('*0*', 3883),\n",
       " ('\"', 3038)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = get_most_common_words(corpus_nltk, n=10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5ba2a",
   "metadata": {},
   "source": [
    "Además se mostrará los primeros 25 tokens del corpus antes y después de la estandarización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1992aee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El',\n",
       " 'grupo',\n",
       " 'estatal',\n",
       " 'Electricité_de_France',\n",
       " '-Fpa-',\n",
       " 'EDF',\n",
       " '-Fpt-',\n",
       " 'anunció',\n",
       " 'hoy',\n",
       " ',',\n",
       " 'jueves',\n",
       " ',',\n",
       " 'la',\n",
       " 'compra',\n",
       " 'del',\n",
       " '51_por_ciento',\n",
       " 'de',\n",
       " 'la',\n",
       " 'empresa',\n",
       " 'mexicana',\n",
       " 'Electricidad_Águila_de_Altamira',\n",
       " '-Fpa-',\n",
       " 'EAA',\n",
       " '-Fpt-',\n",
       " ',']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_nltk[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52dfc8",
   "metadata": {},
   "source": [
    "Como se puede apreciar, hay palabras que tienen `_` en los tokens y separan palabras. Por lo que se harán las funciones específicas para limpiar los tokens y separar las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1230bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_whitespaces(word):\n",
    "    return \"\".join(re.sub('_', ' ', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8df004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_words(word):\n",
    "    return word.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9871df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_without_underscore = [replace_whitespaces(word) for word in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da97fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in corpus_without_underscore:\n",
    "    if len(word.split()) > 1:\n",
    "        corpus.extend(separate_words(word))\n",
    "    else:\n",
    "        corpus.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eadfdb",
   "metadata": {},
   "source": [
    "Además, se puede ver que hay tokens que empiezan con caracteres no alfanuméricos o que contienen caracteres especiales. Específicamente, los siguientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0182525d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reynard/Toyota',\n",
       " '07.30.42',\n",
       " '164,4',\n",
       " '110,37',\n",
       " '5-1',\n",
       " 'CFE-CGC',\n",
       " 'G.P.',\n",
       " '2.500',\n",
       " 'Moet-Hennessy',\n",
       " '1,96']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(word for word in corpus if not word.isalnum()))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a8d19",
   "metadata": {},
   "source": [
    "Como se puede ver, hay palabras que tienen `'`o `\"` en los tokens por lo que *solo* se eliminarán esos caracteres y no el resto del token. En los otros casos, no representan alguna palabra, por lo que se eliminarán completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ce8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    if re.search(r'[^a-zA-Z0-9\\'\"áéíóúÁÉÍÓÚ]', word):\n",
    "        return \"\"\n",
    "    \n",
    "    return re.sub(r'[^a-zA-Z0-9áéíóúÁÉÍÓÚ]', '', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f8d306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [clean_word(word) for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "797c06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word for word in corpus if word != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79840d23",
   "metadata": {},
   "source": [
    "Finalmente, se pondrán las palabras en minúsculas solo si no es sigla o acrónimo. Para esto, se hará una función que verifique si la palabra está en mayúsculas y si no es así, la pondrá en minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab5a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(corpus):\n",
    "    return [word.lower() if not word.isupper() else word for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e15b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = case_folding(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e0851",
   "metadata": {},
   "source": [
    "### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e69630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 11828),\n",
       " ('la', 7150),\n",
       " ('el', 6079),\n",
       " ('que', 5943),\n",
       " ('en', 4991),\n",
       " ('y', 4318),\n",
       " ('a', 3493),\n",
       " ('los', 3229),\n",
       " ('del', 2514),\n",
       " ('las', 1956)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = get_most_common_words(corpus, n=10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbcf2da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el',\n",
       " 'grupo',\n",
       " 'estatal',\n",
       " 'electricité',\n",
       " 'de',\n",
       " 'france',\n",
       " 'EDF',\n",
       " 'anunció',\n",
       " 'hoy',\n",
       " 'jueves',\n",
       " 'la',\n",
       " 'compra',\n",
       " 'del',\n",
       " '51',\n",
       " 'por',\n",
       " 'ciento',\n",
       " 'de',\n",
       " 'la',\n",
       " 'empresa',\n",
       " 'mexicana',\n",
       " 'electricidad',\n",
       " 'águila',\n",
       " 'de',\n",
       " 'altamira',\n",
       " 'EAA']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba8aab",
   "metadata": {},
   "source": [
    "Como se puede apreciar, ya solo hay palabras alfanuméricas y con acentos. Y todas están separadas como se debe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741699f7",
   "metadata": {},
   "source": [
    "## Construcción de n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf4a389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(' '.join(corpus), language='spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeb81122",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens)\n",
    "split = int(0.8 * len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0540f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokens[:split]\n",
    "test  = tokens[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f54614bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens, n):\n",
    "    ngram = Counter( ngrams(tokens, n))\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb05f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_ngram_probs(tokens, k):   \n",
    "    ngram = generate_ngrams(tokens, k)\n",
    "     \n",
    "    if k == 1:\n",
    "        total = sum(ngram.values())\n",
    "        return { (w,): c/total for (w,), c in ngram.items() }\n",
    "    \n",
    "    history_counts = Counter(ngrams(tokens, k-1))\n",
    "    probs = {}\n",
    "    for kgram, c in ngram.items():\n",
    "        history = kgram[:-1]\n",
    "        probs[kgram] = c / history_counts[history]\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c86cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = mle_ngram_probs(train, 1)\n",
    "p2 = mle_ngram_probs(train, 2)\n",
    "p3 = mle_ngram_probs(train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51dc71",
   "metadata": {},
   "source": [
    "## Análisis de espacidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ee47ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(train, test):\n",
    "    seen = { n: set(ngrams(train, n)) for n in range(1, 4) }\n",
    "    results = {}\n",
    "    \n",
    "    for n in range(1, 4):\n",
    "        t_ngrams = list(ngrams(test, n))\n",
    "        unseen = sum(1 for ng in t_ngrams if ng not in seen[n])\n",
    "        results[n] = 100 * unseen / len(t_ngrams) if t_ngrams else 0\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a72866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>% no vistos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.718238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>65.638895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>94.373729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  % no vistos\n",
       "0  1     7.718238\n",
       "1  2    65.638895\n",
       "2  3    94.373729"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_unseen = sparsity(train, test)\n",
    "pct_unseen_df = pd.Series(pct_unseen).rename_axis('n').reset_index(name='% no vistos')\n",
    "pct_unseen_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3c006",
   "metadata": {},
   "source": [
    "Como se puede apreciar, mientras más cantidad de tokens se toma en cuenta para el contexto (n), el porcentaje de ngramas no vistos aumenta. Esto es porque al aumentar el contexto, se reduce la cantidad de ngramas que se pueden generar, ya que se requiere más información para formar un ngrama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17c926",
   "metadata": {},
   "source": [
    "## Suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850028a",
   "metadata": {},
   "source": [
    "### Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11f41456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(tokens, k):\n",
    "    vocab_size = len(set(tokens))\n",
    "    \n",
    "    ngram = generate_ngrams(tokens, k)\n",
    "    \n",
    "    if k == 1:\n",
    "        total = sum(ngram.values())\n",
    "        return { (w,): (c + 1) / (total + vocab_size) for (w,), c in ngram.items() }\n",
    "    \n",
    "    history_counts = Counter(ngrams(tokens, k-1))\n",
    "    probs = {}\n",
    "    for kgram, c in ngram.items():\n",
    "        history = kgram[:-1]\n",
    "        probs[kgram] = (c + 1) / (history_counts[history] + vocab_size)\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "087ab9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_laplace = laplace(train, 1)\n",
    "p2_laplace = laplace(train, 2)\n",
    "p3_laplace = laplace(train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c8248",
   "metadata": {},
   "source": [
    "### Interpolación Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2d2e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1/3, 1/3, 1/3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "753e5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(tokens, k):\n",
    "    all_probs = {}\n",
    "    for n in range(1, k+1):\n",
    "        all_probs[n] = mle_ngram_probs(tokens, n)\n",
    "\n",
    "    ngram_k = generate_ngrams(tokens, k)\n",
    "    interpolated_probs = {}\n",
    "    \n",
    "    for kgram in ngram_k.keys():\n",
    "        prob = 0.0\n",
    "        for n in range(1, k+1):\n",
    "            subgram = kgram[-n:] if n <= len(kgram) else kgram\n",
    "            if subgram in all_probs[n]:\n",
    "                prob += lambdas[n-1] * all_probs[n][subgram]\n",
    "        interpolated_probs[kgram] = prob\n",
    "    \n",
    "    return interpolated_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3567fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_interpolated = linear_interpolation(train, 2)\n",
    "p3_interpolated = linear_interpolation(train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e84e01",
   "metadata": {},
   "source": [
    "### Kneser-Ney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a163e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, padded_vocab = padded_everygram_pipeline(3, train)\n",
    "kn_model = KneserNeyInterpolated(3)\n",
    "kn_model.fit(train_data, padded_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d54e7",
   "metadata": {},
   "source": [
    "## Perplejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3453bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(test_tokens, prob_dict, n, smoothing_type, model=None, sample_size=500):\n",
    "    test_ngrams = list(ngrams(test_tokens, n))\n",
    "    \n",
    "    log_prob_sum = 0\n",
    "    \n",
    "    if smoothing_type == 'kneser_ney':\n",
    "        for ngram in test_ngrams:\n",
    "            try:\n",
    "                context = ngram[:-1] if n > 1 else []\n",
    "                word = ngram[-1]\n",
    "                prob = model.score(word, context)\n",
    "                log_prob_sum += math.log(prob)\n",
    "            except:\n",
    "                log_prob_sum += math.log(1e-6)\n",
    "    else:\n",
    "        vocab_size = len(set(train))\n",
    "        default_prob = 1e-6\n",
    "        \n",
    "        if smoothing_type == 'laplace':\n",
    "            default_prob = 1 / (vocab_size * 2)\n",
    "        \n",
    "        for ngram in test_ngrams:\n",
    "            prob = prob_dict.get(ngram, default_prob)\n",
    "            log_prob_sum += math.log(max(prob, 1e-6))\n",
    "    \n",
    "    if len(test_ngrams) > 0:\n",
    "        avg_log_prob = log_prob_sum / len(test_ngrams)\n",
    "        return math.exp(-avg_log_prob)\n",
    "    else:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a7c1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4a3eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, prob_dict in [(1, p1_laplace), (2, p2_laplace), (3, p3_laplace)]:\n",
    "    perplexity = calculate_perplexity(test, prob_dict, n, 'laplace')\n",
    "    results.append({\n",
    "        'Modelo': f'{n}-grama',\n",
    "        'Técnica': 'Laplace (Add-1)',\n",
    "        'Perplejidad': perplexity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36c524a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, prob_dict in [(2, p2_interpolated), (3, p3_interpolated)]:\n",
    "    perplexity = calculate_perplexity(test, prob_dict, n, 'interpolated')\n",
    "    results.append({\n",
    "        'Modelo': f'{n}-grama',\n",
    "        'Técnica': 'Interpolación lineal',\n",
    "        'Perplejidad': perplexity\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5aa38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_perplexity = calculate_perplexity(test, None, 3, 'kneser_ney', kn_model)\n",
    "kn_perplexity = kn_perplexity if kn_perplexity != float('inf') else 'Inf'\n",
    "results.append({\n",
    "    'Modelo': '3-grama',\n",
    "    'Técnica': 'Kneser-Ney',\n",
    "    'Perplejidad': kn_perplexity if kn_perplexity != float('inf') else 'Inf'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fb71f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Técnica</th>\n",
       "      <th>Perplejidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-grama</td>\n",
       "      <td>Laplace (Add-1)</td>\n",
       "      <td>1192.103956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-grama</td>\n",
       "      <td>Laplace (Add-1)</td>\n",
       "      <td>12791.897088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-grama</td>\n",
       "      <td>Laplace (Add-1)</td>\n",
       "      <td>34595.715186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-grama</td>\n",
       "      <td>Interpolación lineal</td>\n",
       "      <td>49230.063398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-grama</td>\n",
       "      <td>Interpolación lineal</td>\n",
       "      <td>558977.323530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3-grama</td>\n",
       "      <td>Kneser-Ney</td>\n",
       "      <td>607222.414957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo               Técnica    Perplejidad\n",
       "0  1-grama       Laplace (Add-1)    1192.103956\n",
       "1  2-grama       Laplace (Add-1)   12791.897088\n",
       "2  3-grama       Laplace (Add-1)   34595.715186\n",
       "3  2-grama  Interpolación lineal   49230.063398\n",
       "4  3-grama  Interpolación lineal  558977.323530\n",
       "5  3-grama            Kneser-Ney  607222.414957"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Perplejidad')\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
