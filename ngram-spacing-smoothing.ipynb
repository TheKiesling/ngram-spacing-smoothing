{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa56939",
   "metadata": {},
   "source": [
    "# Ngram Spacing and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0239771",
   "metadata": {},
   "source": [
    "### José Pablo Kiesling Lange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadfcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm import KneserNeyInterpolated\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a02488",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61eefee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\TheKi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TheKi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('cess_esp')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7add29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_nltk = cess_esp.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787263b",
   "metadata": {},
   "source": [
    "## Estandarización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874093d",
   "metadata": {},
   "source": [
    "Para ver la efectivdad de la estandarización, se mostrará las 10 palabras más frecuentes del corpus antes y después de la estandarización. El objetivo es ver si hay modificación en la cantidad de dichas palabras o si una nueva palabra aparece con frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d8d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2567f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(corpus, n=10):\n",
    "    words = [word for line in corpus for word in line.split()]\n",
    "    most_common = Counter(words).most_common(n)\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b12f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 11420),\n",
       " ('de', 10234),\n",
       " ('la', 6412),\n",
       " ('.', 5866),\n",
       " ('que', 5552),\n",
       " ('el', 5199),\n",
       " ('en', 4340),\n",
       " ('y', 4235),\n",
       " ('*0*', 3883),\n",
       " ('\"', 3038)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = get_most_common_words(corpus_nltk, n=10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5ba2a",
   "metadata": {},
   "source": [
    "Además se mostrará los primeros 25 tokens del corpus antes y después de la estandarización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1992aee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El',\n",
       " 'grupo',\n",
       " 'estatal',\n",
       " 'Electricité_de_France',\n",
       " '-Fpa-',\n",
       " 'EDF',\n",
       " '-Fpt-',\n",
       " 'anunció',\n",
       " 'hoy',\n",
       " ',',\n",
       " 'jueves',\n",
       " ',',\n",
       " 'la',\n",
       " 'compra',\n",
       " 'del',\n",
       " '51_por_ciento',\n",
       " 'de',\n",
       " 'la',\n",
       " 'empresa',\n",
       " 'mexicana',\n",
       " 'Electricidad_Águila_de_Altamira',\n",
       " '-Fpa-',\n",
       " 'EAA',\n",
       " '-Fpt-',\n",
       " ',']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_nltk[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52dfc8",
   "metadata": {},
   "source": [
    "Como se puede apreciar, hay palabras que tienen `_` en los tokens y separan palabras. Por lo que se harán las funciones específicas para limpiar los tokens y separar las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1230bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_whitespaces(word):\n",
    "    return \"\".join(re.sub('_', ' ', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8df004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_words(word):\n",
    "    return word.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9871df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_without_underscore = [replace_whitespaces(word) for word in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da97fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in corpus_without_underscore:\n",
    "    if len(word.split()) > 1:\n",
    "        corpus.extend(separate_words(word))\n",
    "    else:\n",
    "        corpus.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eadfdb",
   "metadata": {},
   "source": [
    "Además, se puede ver que hay tokens que empiezan con caracteres no alfanuméricos o que contienen caracteres especiales. Específicamente, los siguientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0182525d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anglo-alemán',\n",
       " '15,08',\n",
       " '16-3',\n",
       " '7-5',\n",
       " '164,4',\n",
       " \"Barcelona'92\",\n",
       " '3-1',\n",
       " \"P'hrabat\",\n",
       " '2-6',\n",
       " 'uruguayo-mexicano']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(word for word in corpus if not word.isalnum()))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a8d19",
   "metadata": {},
   "source": [
    "Como se puede ver, hay palabras que tienen `'`o `\"` en los tokens por lo que *solo* se eliminarán esos caracteres y no el resto del token. En los otros casos, no representan alguna palabra, por lo que se eliminarán completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ce8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    if re.search(r'[^a-zA-Z0-9\\'\"áéíóúÁÉÍÓÚ]', word):\n",
    "        return \"\"\n",
    "    \n",
    "    return re.sub(r'[^a-zA-Z0-9áéíóúÁÉÍÓÚ]', '', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f8d306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [clean_word(word) for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "797c06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word for word in corpus if word != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79840d23",
   "metadata": {},
   "source": [
    "Finalmente, se pondrán las palabras en minúsculas solo si no es sigla o acrónimo. Para esto, se hará una función que verifique si la palabra está en mayúsculas y si no es así, la pondrá en minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab5a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(corpus):\n",
    "    return [word.lower() if not word.isupper() else word for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e15b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = case_folding(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e0851",
   "metadata": {},
   "source": [
    "### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e69630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 11828),\n",
       " ('la', 7150),\n",
       " ('el', 6079),\n",
       " ('que', 5943),\n",
       " ('en', 4991),\n",
       " ('y', 4318),\n",
       " ('a', 3493),\n",
       " ('los', 3229),\n",
       " ('del', 2514),\n",
       " ('las', 1956)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = get_most_common_words(corpus, n=10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbcf2da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el',\n",
       " 'grupo',\n",
       " 'estatal',\n",
       " 'electricité',\n",
       " 'de',\n",
       " 'france',\n",
       " 'EDF',\n",
       " 'anunció',\n",
       " 'hoy',\n",
       " 'jueves',\n",
       " 'la',\n",
       " 'compra',\n",
       " 'del',\n",
       " '51',\n",
       " 'por',\n",
       " 'ciento',\n",
       " 'de',\n",
       " 'la',\n",
       " 'empresa',\n",
       " 'mexicana',\n",
       " 'electricidad',\n",
       " 'águila',\n",
       " 'de',\n",
       " 'altamira',\n",
       " 'EAA']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba8aab",
   "metadata": {},
   "source": [
    "Como se puede apreciar, ya solo hay palabras alfanuméricas y con acentos. Y todas están separadas como se debe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741699f7",
   "metadata": {},
   "source": [
    "## Construcción de n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf4a389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(' '.join(corpus), language='spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeb81122",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens)\n",
    "split = int(0.8 * len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0540f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokens[:split]\n",
    "test  = tokens[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f54614bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens, n):\n",
    "    ngram = Counter( ngrams(tokens, n))\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb05f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_ngram_probs(tokens, k):   \n",
    "    ngram = generate_ngrams(tokens, k)\n",
    "     \n",
    "    if k == 1:\n",
    "        total = sum(ngram.values())\n",
    "        return { (w,): c/total for (w,), c in ngram.items() }\n",
    "    \n",
    "    history_counts = Counter(ngrams(tokens, k-1))\n",
    "    probs = {}\n",
    "    for kgram, c in ngram.items():\n",
    "        history = kgram[:-1]\n",
    "        probs[kgram] = c / history_counts[history]\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c86cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = mle_ngram_probs(train, 1)\n",
    "p2 = mle_ngram_probs(train, 2)\n",
    "p3 = mle_ngram_probs(train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51dc71",
   "metadata": {},
   "source": [
    "## Análisis de espacidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ee47ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(train, test):\n",
    "    seen = { n: set(ngrams(train, n)) for n in range(1, 4) }\n",
    "    results = {}\n",
    "    \n",
    "    for n in range(1, 4):\n",
    "        t_ngrams = list(ngrams(test, n))\n",
    "        unseen = sum(1 for ng in t_ngrams if ng not in seen[n])\n",
    "        results[n] = 100 * unseen / len(t_ngrams) if t_ngrams else 0\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a72866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>% no vistos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.718238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>65.638895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>94.373729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  % no vistos\n",
       "0  1     7.718238\n",
       "1  2    65.638895\n",
       "2  3    94.373729"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_unseen = sparsity(train, test)\n",
    "pct_unseen_df = pd.Series(pct_unseen).rename_axis('n').reset_index(name='% no vistos')\n",
    "pct_unseen_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3c006",
   "metadata": {},
   "source": [
    "Como se puede apreciar, mientras más cantidad de tokens se toma en cuenta para el contexto (n), el porcentaje de ngramas no vistos aumenta. Esto es porque al aumentar el contexto, se reduce la cantidad de ngramas que se pueden generar, ya que se requiere más información para formar un ngrama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17c926",
   "metadata": {},
   "source": [
    "## Suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850028a",
   "metadata": {},
   "source": [
    "### Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11f41456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_probs(tokens, k):\n",
    "    V = len(set(tokens))\n",
    "    counts_k = Counter(ngrams(tokens, k))\n",
    "    if k == 1:\n",
    "        total = sum(counts_k.values())\n",
    "        return { (w,): (c+1)/(total+V) for (w,), c in counts_k.items() }\n",
    "    counts_hist = Counter(ngrams(tokens, k-1))\n",
    "    return { kgram: (c+1)/(counts_hist[kgram[:-1]]+V) for kgram, c in counts_k.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88e7a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = laplace_probs(train, 1)\n",
    "l2 = laplace_probs(train, 2)\n",
    "l3 = laplace_probs(train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c8248",
   "metadata": {},
   "source": [
    "### Interpolación Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2d2e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1/3, 1/3, 1/3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "753e5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_prob(context, word):\n",
    "    uni = p1.get((word,), 0)\n",
    "    bi  = p2.get((context[-1], word), 0) if len(context)>=1 else 0\n",
    "    tri = p3.get((context[-2], context[-1], word), 0) if len(context)>=2 else 0\n",
    "    return lambdas[0]*uni + lambdas[1]*bi + lambdas[2]*tri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e84e01",
   "metadata": {},
   "source": [
    "### Kneser-Ney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a163e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, padded_vocab = padded_everygram_pipeline(3, train)\n",
    "kn_model = KneserNeyInterpolated(3)\n",
    "kn_model.fit(train_data, padded_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
